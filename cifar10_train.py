# -*- coding: utf-8 -*-
"""Cifar10_train

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zvUMH2BmZFkU3jz42WCnl3zSZLKJQ2dK
"""

import keras
from keras.datasets import cifar10
from keras.layers import Conv2D, BatchNormalization, Dense, Dropout, MaxPooling2D, AveragePooling2D,Activation, Flatten
from keras.models import Model, Input
from keras.callbacks import LearningRateScheduler
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
import os
from math import ceil

#load dataset
(train_x, train_y), (test_x, test_y) = cifar10.load_data()

#normalize the pixel values of images
train_x = train_x.astype('float32')/255
test_x = test_x.astype('float32')/255

#subtract mean image from the images for the purpose of data augmentation
train_x = train_x - train_x.mean()
test_x = test_x - test_x.mean()

#divide by standard deviation
train_x = train_x/train_x.std(axis = 0)
test_x = test_x/test_x.std(axis = 0)

#convert labels to vectors
train_y = keras.utils.to_categorical(train_y, 10)
test_y = keras.utils.to_categorical(test_y, 10)


def module(x, filters):

    out = BatchNormalization()(x)
    out = Activation("relu")(out)
    out = Conv2D(filters = filters, kernel_size = [3,3], strides = [1,1], padding = "same")(out)

    out = BatchNormalization()(out)
    out = Activation("relu")(out)
    out = Conv2D(filters = filters, kernel_size = [3,3], strides = [1,1], padding = "same")(out)

    return out


def model_structure(input_shape):
    images = Input(input_shape)

    net = Conv2D(filters = 32, kernel_size = [3,3], strides = [1,1], padding = "same")(images)

    net = module(net, 32)
    net = module(net, 32)
    net = module(net, 32)
    net = MaxPooling2D(pool_size = (2,2))(net)

    net = module(net, 64)
    net = module(net, 64)
    net = module(net, 64)
    net = MaxPooling2D(pool_size = (2,2))(net)

    net = module(net, 128)
    net = module(net, 128)
    net = module(net, 128)

    net = Dropout(0.20)(net)
    net = AveragePooling2D(pool_size = (8,8))(net)
    net = Flatten()(net)
    net = Dense(units = 10, activation = "softmax")(net)

    model = Model(inputs = images, outputs = net)
    return model

#dimension of the input images, Width * Height * Channels
input_shape = (32,32, 3)  
model = model_structure(input_shape)
model.summary() 

def lr_train(epoch):
    lr = 0.001
    if epoch > 25:
        lr = lr/120
    elif epoch > 20:
        lr = lr/100
    elif epoch > 15:
        lr = lr/50
    elif epoch > 10:
        lr = lr/10
    elif epoch > 5:
        lr = lr/5
    

    print("Learning Rate ", lr)    

    return lr 
    
	
lr_scheduler = LearningRateScheduler(lr_train)

model.compile(optimizer = Adam(lr_train(0)), loss = "categorical_crossentropy", metrics = ["accuracy"])

datagen = ImageDataGenerator(rotation_range = 20, width_shift_range = 5/32, height_shift_range = 5/32)

batch_size = 32
epochs = 30
steps_per_epoch = ceil(50000/32)

model.fit_generator(datagen.flow(train_x, train_y, batch_size=batch_size), validation_data=[test_x,test_y], epochs=epochs,steps_per_epoch=steps_per_epoch)

#Evaluate model
accuracy = model.evaluate(test_x, test_y)
print("Accuracy: ", accuracy[1])